{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification on Spark with GPU\n",
    "\n",
    "This demo is to show how you can leverage Spark 3.0 with GPU sharing feature on a standalone cluster. In our setup, we will create a Spark cluster with 1 master and 1 worker. We would strongly recommend to run this Notebook in [Amazon SageMaker Notebook](https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html) since the tutorial is setup and tested on this platform.\n",
    "\n",
    "## Setup\n",
    "\n",
    "You may need to switch the system default CUDA version by following [instruction](https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-base.html)\n",
    "\n",
    "```bash\n",
    "sudo rm /usr/local/cuda\n",
    "sudo ln -s /usr/local/cuda-10.1 /usr/local/cuda\n",
    "nvcc --version\n",
    "```\n",
    "\n",
    "Currently, DJL can work with CUDA 10.1 and 10.2.\n",
    "\n",
    "Let's start by spawn a terminal in JupyterLab. Please follow our [SageMaker Setup](https://github.com/aws-samples/djl-demo/tree/master/aws/sagemaker-notebook) with Scala Kernel and Spark.\n",
    "\n",
    "After follow the instruction, you should have a Spark standalone cluster setup.\n",
    "\n",
    "## Import dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.0.1`\n",
    "import $ivy.`org.apache.spark::spark-mllib:3.0.1`\n",
    "import $ivy.`org.apache.hadoop:hadoop-hdfs:2.7.4`\n",
    "import $ivy.`ai.djl:api:0.8.0`\n",
    "import $ivy.`ai.djl.pytorch:pytorch-model-zoo:0.8.0`\n",
    "import $ivy.`ai.djl.pytorch:pytorch-native-auto:1.6.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.net.URL\n",
    "import java.nio.file.Files\n",
    "import java.util\n",
    "import ai.djl.{Device, Model}\n",
    "import ai.djl.modality.Classifications\n",
    "import ai.djl.modality.cv.transform.{Resize, ToTensor}\n",
    "import ai.djl.ndarray.types.{DataType, Shape}\n",
    "import ai.djl.ndarray.{NDList, NDManager}\n",
    "import ai.djl.repository.zoo.{Criteria, ModelZoo, ZooModel}\n",
    "import ai.djl.training.util.{DownloadUtils, ProgressBar}\n",
    "import ai.djl.translate.{Batchifier, Pipeline, Translator, TranslatorContext}\n",
    "import ai.djl.util.{Utils, ZipUtils}\n",
    "import org.apache.hadoop.conf.Configuration\n",
    "import org.apache.hadoop.fs.{FileSystem, Path}\n",
    "import org.apache.spark.{SparkConf, TaskContext}\n",
    "import org.apache.spark.ml.image.ImageSchema\n",
    "import org.apache.spark.sql.functions.col\n",
    "import org.apache.spark.sql.{Encoders, Row, NotebookSparkSession}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val url = \"https://alpha-djl-demos.s3.amazonaws.com/spark-demo/images.zip\"\n",
    "val tempPath = Files.createTempDirectory(\"images\")\n",
    "DownloadUtils.download(new URL(url), tempPath.resolve(\"images.zip\"), new ProgressBar())\n",
    "ZipUtils.unzip(Files.newInputStream(tempPath.resolve(\"images.zip\")), tempPath)\n",
    "// upload to hadoop\n",
    "println(\"Upload images to HDFS...\")\n",
    "val hadoopConf = new Configuration()\n",
    "val hdfs = FileSystem.get(hadoopConf)\n",
    "val srcPath = new Path(tempPath.toAbsolutePath.toString)\n",
    "val outputPath = new Path(\"hdfs:///images\")\n",
    "hdfs.copyFromLocalFile(srcPath, outputPath)\n",
    "val imagePath = outputPath.toString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Translator\n",
    "\n",
    "A Translator in DJL is used to define the preprocessing and postprocessing logic. The following code is to \n",
    "\n",
    "- preprocess: convert a Spark DataFrame Row to DJL NDArray.\n",
    "- postprocess: convert inference result to classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Translator: a class used to do preprocessing and post processing\n",
    "class MyTranslator extends Translator[Row, Classifications] {\n",
    "\n",
    "    private var classes: java.util.List[String] = new util.ArrayList[String]()\n",
    "    private val pipeline: Pipeline = new Pipeline()\n",
    "      .add(new Resize(224, 224))\n",
    "      .add(new ToTensor())\n",
    "\n",
    "    override def prepare(manager: NDManager, model: Model): Unit = {\n",
    "        classes = Utils.readLines(model.getArtifact(\"synset.txt\").openStream())\n",
    "      }\n",
    "\n",
    "    override def processInput(ctx: TranslatorContext, row: Row): NDList = {\n",
    "\n",
    "      val height = ImageSchema.getHeight(row)\n",
    "      val width = ImageSchema.getWidth(row)\n",
    "      val channel = ImageSchema.getNChannels(row)\n",
    "      var image = ctx.getNDManager.create(ImageSchema.getData(row), new Shape(height, width, channel)).toType(DataType.UINT8, true)\n",
    "      // BGR to RGB\n",
    "      image = image.flip(2)\n",
    "      pipeline.transform(new NDList(image))\n",
    "    }\n",
    "\n",
    "    // Deal with the output.ï¼ŒNDList contains output result, usually one or more NDArray(s).\n",
    "    override def processOutput(ctx: TranslatorContext, list: NDList): Classifications = {\n",
    "      var probabilitiesNd = list.singletonOrThrow\n",
    "      probabilitiesNd = probabilitiesNd.softmax(0)\n",
    "      new Classifications(classes, probabilitiesNd)\n",
    "    }\n",
    "\n",
    "    override def getBatchifier: Batchifier = Batchifier.STACK\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model\n",
    "\n",
    "Now, we just need to fetch the model from a URL. The url can be a hdfs (hdfs://), file (file://) or http (https://) format. We use Criteria as a container to store the model and translator information. Then, all we need to do is to load the model from it.\n",
    "\n",
    "Note: DJL Criteria and Model are not serializable, so we add `lazy` declaration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val modelUrl = \"https://alpha-djl-demos.s3.amazonaws.com/model/djl-blockrunner/pytorch_resnet18.zip?model_name=traced_resnet18\"\n",
    "lazy val criteria = Criteria.builder\n",
    "  .setTypes(classOf[Row], classOf[Classifications])\n",
    "  .optModelUrls(modelUrl)\n",
    "  .optTranslator(new MyTranslator())\n",
    "  .optProgress(new ProgressBar)\n",
    "  .build()\n",
    "lazy val model = ModelZoo.loadModel(criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Spark application\n",
    "\n",
    "We can create a `NotebookSparkSession` through the Almond Spark plugin. It will internally apply all necessary jars to each of the worker node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create Spark session\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"spark://localhost:7077\")\n",
    "    .config(\"spark.task.resource.gpu.amount\", \"0.25\")\n",
    "    .config(\"spark.task.cpus\", \"2\")\n",
    "    .config(\"spark.executor.resource.gpu.amount\", \"1\")\n",
    "    .getOrCreate()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.getAll.foreach(pair => println(pair._1 + \":\" + pair._2))\n",
    "val df = spark.read.format(\"image\").option(\"dropInvalid\", true).load(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val result = df.select(col(\"image.*\")).mapPartitions(partition => {\n",
    "  val context = TaskContext.get()\n",
    "  val gpu = context.resources()(\"gpu\").addresses(0)\n",
    "  val model = loadModel(Device.gpu(gpu.toInt))\n",
    "  val predictor = model.newPredictor()\n",
    "  partition.map(row => {\n",
    "    // image data stored as HWC format\n",
    "    predictor.predict(row).toString\n",
    "  })\n",
    "})(Encoders.STRING)\n",
    "println(result.collect().mkString(\"\\n\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
